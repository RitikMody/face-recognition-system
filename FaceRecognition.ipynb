{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FaceRecognition",
      "provenance": [],
      "collapsed_sections": []
    },
    "coursera": {
      "course_slug": "convolutional-neural-networks",
      "graded_item_id": "IaknP",
      "launcher_item_id": "5UMr4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kl1JNj7lziu8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_lfw_people\n",
        "from sklearn.datasets import fetch_lfw_pairs\n",
        "import os\n",
        "import keras.backend as K\n",
        "from keras.models import Model, Sequential,load_model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Input, Subtract, Lambda,Dropout,Concatenate,GlobalAveragePooling2D,BatchNormalization\n",
        "from keras.optimizers import Adam, SGD , RMSprop\n",
        "from keras.regularizers import l2\n",
        "import keras.backend as K\n",
        "from keras import activations\n",
        "from keras import applications\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Optimizer\n",
        "import numpy as np\n",
        "from keras.callbacks import EarlyStopping , ModelCheckpoint\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.applications import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Lx7EDnQGcQq",
        "outputId": "90f84f22-3d40-4ccb-a359-6cab601986c5"
      },
      "source": [
        "!pip install deepface"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deepface\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/3b/6fac01699c593d72ff3c915d774bdc479e8da25e539da8011ab91d05ef6a/deepface-0.0.50-py3-none-any.whl (56kB)\n",
            "\r\u001b[K     |█████▊                          | 10kB 22.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 20kB 28.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 30kB 19.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 40kB 23.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 51kB 17.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n",
            "\u001b[?25hCollecting gdown>=3.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.5)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.4.1)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (2.4.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.19.5)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (7.1.2)\n",
            "Collecting mtcnn>=0.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/43/abee91792797c609c1bf30f1112117f7a87a713ebaa6ec5201d5555a73ef/mtcnn-0.1.0-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 26.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3.4.4 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.1.2.30)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.7/dist-packages (from deepface) (4.41.1)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from deepface) (1.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (1.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (3.0.12)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from gdown>=3.10.1->deepface) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.4->deepface) (2.8.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.12.4)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.12.1)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.12.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (0.36.2)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (3.7.4.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (2.4.1)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.32.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=1.9.0->deepface) (1.12)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.0->deepface) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras>=2.2.0->deepface) (1.4.1)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=1.1.2->deepface) (1.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow>=1.9.0->deepface) (54.2.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.9.0->deepface) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.9.0->deepface) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.9.0->deepface) (1.28.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow>=1.9.0->deepface) (3.3.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->Flask>=1.1.2->deepface) (1.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.9.0->deepface) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.9.0->deepface) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.9.0->deepface) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.9.0->deepface) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.9.0->deepface) (3.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow>=1.9.0->deepface) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow>=1.9.0->deepface) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow>=1.9.0->deepface) (3.4.1)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-cp37-none-any.whl size=9693 sha256=95fec69970f4a67f97ca5a878e0cbb6b41468ee783de807671ef647fc31ab3d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
            "Successfully built gdown\n",
            "Installing collected packages: gdown, mtcnn, deepface\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed deepface-0.0.50 gdown-3.12.2 mtcnn-0.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tJdTcj6Ga9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e861e12-2b46-4ba9-fa67-9dac554ba654"
      },
      "source": [
        "from deepface import DeepFace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuK8y5KMGtmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd2411d-5240-4fb8-bcaf-44935c5fbf97"
      },
      "source": [
        "net = DeepFace.OpenFace.loadModel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "openface_weights.h5 will be downloaded...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1LSe1YCV1x-BfNnfb7DFZTNpv_Q9jITxn\n",
            "To: /root/.deepface/weights/openface_weights.h5\n",
            "15.3MB [00:00, 168MB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nExalmcdHFr2",
        "outputId": "c82a0afb-c708-4061-b6bb-c514d64a64f5"
      },
      "source": [
        "net.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 96, 96, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 102, 102, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 48, 48, 64)   9472        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn1 (BatchNormalization)        (None, 48, 48, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 48, 48, 64)   0           bn1[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 50, 50, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 24, 24, 64)   0           zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "lrn_1 (Lambda)                  (None, 24, 24, 64)   0           max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2 (Conv2D)                  (None, 24, 24, 64)   4160        lrn_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "bn2 (BatchNormalization)        (None, 24, 24, 64)   256         conv2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 24, 24, 64)   0           bn2[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, 26, 26, 64)   0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv3 (Conv2D)                  (None, 24, 24, 192)  110784      zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn3 (BatchNormalization)        (None, 24, 24, 192)  768         conv3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 24, 24, 192)  0           bn3[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "lrn_2 (Lambda)                  (None, 24, 24, 192)  0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, 26, 26, 192)  0           lrn_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 12, 12, 192)  0           zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_3x3_conv1 (Conv2D) (None, 12, 12, 96)   18528       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_5x5_conv1 (Conv2D) (None, 12, 12, 16)   3088        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3a_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_5x5_bn1 (BatchNorm (None, 12, 12, 16)   64          inception_3a_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 12, 12, 96)   0           inception_3a_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 12, 12, 16)   0           inception_3a_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 192)    0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, 14, 14, 96)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, 16, 16, 16)   0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_pool_conv (Conv2D) (None, 5, 5, 32)     6176        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_5x5_conv2 (Conv2D) (None, 12, 12, 32)   12832       zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_pool_bn (BatchNorm (None, 5, 5, 32)     128         inception_3a_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_1x1_conv (Conv2D)  (None, 12, 12, 64)   12352       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3a_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_5x5_bn2 (BatchNorm (None, 12, 12, 32)   128         inception_3a_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 5, 5, 32)     0           inception_3a_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_3a_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 12, 12, 128)  0           inception_3a_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 12, 12, 32)   0           inception_3a_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_6 (ZeroPadding2D (None, 12, 12, 32)   0           activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 12, 12, 64)   0           inception_3a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 12, 12, 256)  0           activation_4[0][0]               \n",
            "                                                                 activation_6[0][0]               \n",
            "                                                                 zero_padding2d_6[0][0]           \n",
            "                                                                 activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "power2_3b (Lambda)              (None, 12, 12, 256)  0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_3x3_conv1 (Conv2D) (None, 12, 12, 96)   24672       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_5x5_conv1 (Conv2D) (None, 12, 12, 32)   8224        concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 4, 4, 256)    0           power2_3b[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_3x3_bn1 (BatchNorm (None, 12, 12, 96)   384         inception_3b_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3b_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mult9_3b (Lambda)               (None, 4, 4, 256)    0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 12, 12, 96)   0           inception_3b_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 12, 12, 32)   0           inception_3b_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sqrt_3b (Lambda)                (None, 4, 4, 256)    0           mult9_3b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_7 (ZeroPadding2D (None, 14, 14, 96)   0           activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_8 (ZeroPadding2D (None, 16, 16, 32)   0           activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_pool_conv (Conv2D) (None, 4, 4, 64)     16448       sqrt_3b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_3x3_conv2 (Conv2D) (None, 12, 12, 128)  110720      zero_padding2d_7[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_5x5_conv2 (Conv2D) (None, 12, 12, 64)   51264       zero_padding2d_8[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_pool_bn (BatchNorm (None, 4, 4, 64)     256         inception_3b_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_1x1_conv (Conv2D)  (None, 12, 12, 64)   16448       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_3x3_bn2 (BatchNorm (None, 12, 12, 128)  512         inception_3b_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_5x5_bn2 (BatchNorm (None, 12, 12, 64)   256         inception_3b_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 4, 4, 64)     0           inception_3b_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_3b_1x1_bn (BatchNorma (None, 12, 12, 64)   256         inception_3b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 12, 12, 128)  0           inception_3b_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 12, 12, 64)   0           inception_3b_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_9 (ZeroPadding2D (None, 12, 12, 64)   0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 12, 12, 64)   0           inception_3b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 12, 12, 320)  0           activation_10[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "                                                                 zero_padding2d_9[0][0]           \n",
            "                                                                 activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_3x3_conv1 (Conv2D) (None, 12, 12, 128)  41088       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_5x5_conv1 (Conv2D) (None, 12, 12, 32)   10272       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_3x3_bn1 (BatchNorm (None, 12, 12, 128)  512         inception_3c_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_5x5_bn1 (BatchNorm (None, 12, 12, 32)   128         inception_3c_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 12, 12, 128)  0           inception_3c_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 12, 12, 32)   0           inception_3c_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_10 (ZeroPadding2 (None, 14, 14, 128)  0           activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_11 (ZeroPadding2 (None, 16, 16, 32)   0           activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_3x3_conv2 (Conv2D) (None, 6, 6, 256)    295168      zero_padding2d_10[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_11[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_3x3_bn2 (BatchNorm (None, 6, 6, 256)    1024        inception_3c_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_3c_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_3c_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 320)    0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 6, 6, 256)    0           inception_3c_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 6, 6, 64)     0           inception_3c_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_12 (ZeroPadding2 (None, 6, 6, 320)    0           max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 6, 6, 640)    0           activation_16[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 zero_padding2d_12[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "power2_4a (Lambda)              (None, 6, 6, 640)    0           concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_3x3_conv1 (Conv2D) (None, 6, 6, 96)     61536       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_5x5_conv1 (Conv2D) (None, 6, 6, 32)     20512       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 2, 2, 640)    0           power2_4a[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_3x3_bn1 (BatchNorm (None, 6, 6, 96)     384         inception_4a_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_5x5_bn1 (BatchNorm (None, 6, 6, 32)     128         inception_4a_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mult9_4a (Lambda)               (None, 2, 2, 640)    0           average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 6, 6, 96)     0           inception_4a_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 6, 6, 32)     0           inception_4a_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sqrt_4a (Lambda)                (None, 2, 2, 640)    0           mult9_4a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_13 (ZeroPadding2 (None, 8, 8, 96)     0           activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_14 (ZeroPadding2 (None, 10, 10, 32)   0           activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_pool_conv (Conv2D) (None, 2, 2, 128)    82048       sqrt_4a[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_3x3_conv2 (Conv2D) (None, 6, 6, 192)    166080      zero_padding2d_13[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_5x5_conv2 (Conv2D) (None, 6, 6, 64)     51264       zero_padding2d_14[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_pool_bn (BatchNorm (None, 2, 2, 128)    512         inception_4a_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_1x1_conv (Conv2D)  (None, 6, 6, 256)    164096      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_3x3_bn2 (BatchNorm (None, 6, 6, 192)    768         inception_4a_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_5x5_bn2 (BatchNorm (None, 6, 6, 64)     256         inception_4a_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 2, 2, 128)    0           inception_4a_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_4a_1x1_bn (BatchNorma (None, 6, 6, 256)    1024        inception_4a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 6, 6, 192)    0           inception_4a_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 6, 6, 64)     0           inception_4a_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_15 (ZeroPadding2 (None, 6, 6, 128)    0           activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 6, 6, 256)    0           inception_4a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 6, 6, 640)    0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 zero_padding2d_15[0][0]          \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_3x3_conv1 (Conv2D) (None, 6, 6, 160)    102560      concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_5x5_conv1 (Conv2D) (None, 6, 6, 64)     41024       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_3x3_bn1 (BatchNorm (None, 6, 6, 160)    640         inception_4e_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_5x5_bn1 (BatchNorm (None, 6, 6, 64)     256         inception_4e_5x5_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 6, 6, 160)    0           inception_4e_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 6, 6, 64)     0           inception_4e_5x5_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_16 (ZeroPadding2 (None, 8, 8, 160)    0           activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_17 (ZeroPadding2 (None, 10, 10, 64)   0           activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_3x3_conv2 (Conv2D) (None, 3, 3, 256)    368896      zero_padding2d_16[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_5x5_conv2 (Conv2D) (None, 3, 3, 128)    204928      zero_padding2d_17[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_3x3_bn2 (BatchNorm (None, 3, 3, 256)    1024        inception_4e_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_4e_5x5_bn2 (BatchNorm (None, 3, 3, 128)    512         inception_4e_5x5_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 640)    0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 3, 3, 256)    0           inception_4e_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 3, 3, 128)    0           inception_4e_5x5_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_18 (ZeroPadding2 (None, 3, 3, 640)    0           max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 3, 3, 1024)   0           activation_26[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "                                                                 zero_padding2d_18[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "power2_5a (Lambda)              (None, 3, 3, 1024)   0           concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_3x3_conv1 (Conv2D) (None, 3, 3, 96)     98400       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 1024)   0           power2_5a[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5a_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mult9_5a (Lambda)               (None, 1, 1, 1024)   0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 3, 3, 96)     0           inception_5a_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "sqrt_5a (Lambda)                (None, 1, 1, 1024)   0           mult9_5a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_19 (ZeroPadding2 (None, 5, 5, 96)     0           activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_pool_conv (Conv2D) (None, 1, 1, 96)     98400       sqrt_5a[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_19[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5a_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_1x1_conv (Conv2D)  (None, 3, 3, 256)    262400      concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5a_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 1, 1, 96)     0           inception_5a_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_5a_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5a_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 3, 3, 384)    0           inception_5a_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_20 (ZeroPadding2 (None, 3, 3, 96)     0           activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 3, 3, 256)    0           inception_5a_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 3, 3, 736)    0           activation_30[0][0]              \n",
            "                                                                 zero_padding2d_20[0][0]          \n",
            "                                                                 activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_3x3_conv1 (Conv2D) (None, 3, 3, 96)     70752       concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_3x3_bn1 (BatchNorm (None, 3, 3, 96)     384         inception_5b_3x3_conv1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 3, 3, 96)     0           inception_5b_3x3_bn1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 736)    0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_21 (ZeroPadding2 (None, 5, 5, 96)     0           activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_pool_conv (Conv2D) (None, 1, 1, 96)     70752       max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_3x3_conv2 (Conv2D) (None, 3, 3, 384)    332160      zero_padding2d_21[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_pool_bn (BatchNorm (None, 1, 1, 96)     384         inception_5b_pool_conv[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_1x1_conv (Conv2D)  (None, 3, 3, 256)    188672      concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_3x3_bn2 (BatchNorm (None, 3, 3, 384)    1536        inception_5b_3x3_conv2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 1, 1, 96)     0           inception_5b_pool_bn[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "inception_5b_1x1_bn (BatchNorma (None, 3, 3, 256)    1024        inception_5b_1x1_conv[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 3, 3, 384)    0           inception_5b_3x3_bn2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_22 (ZeroPadding2 (None, 3, 3, 96)     0           activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 3, 3, 256)    0           inception_5b_1x1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_6 (Concatenate)     (None, 3, 3, 736)    0           activation_34[0][0]              \n",
            "                                                                 zero_padding2d_22[0][0]          \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 1, 1, 736)    0           concatenate_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 736)          0           average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_layer (Dense)             (None, 128)          94336       flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "norm_layer (Lambda)             (None, 128)          0           dense_layer[0][0]                \n",
            "==================================================================================================\n",
            "Total params: 3,743,280\n",
            "Trainable params: 3,733,968\n",
            "Non-trainable params: 9,312\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQLvLBw7HFvr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7N7KZX62fi7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63ebe8ab-38e9-4840-9822-03146723d0a9"
      },
      "source": [
        "image_slice=(slice(70, 195), slice(65, 190))\n",
        "from sklearn.datasets import fetch_lfw_pairs\n",
        "lfw_pairs_train = fetch_lfw_pairs(subset='train',funneled=True,resize=96/125,slice_=image_slice,color=True)\n",
        "lfw_pairs_test = fetch_lfw_pairs(subset='test',funneled=True,resize=96/125,slice_=image_slice,color=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976012\n",
            "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976009\n",
            "Downloading LFW metadata: https://ndownloader.figshare.com/files/5976006\n",
            "Downloading LFW data (~200MB): https://ndownloader.figshare.com/files/5976015\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScNdfsLeb5lV",
        "outputId": "84494163-18c1-4870-d555-ff5659b95801"
      },
      "source": [
        "lfw_pairs_train.pairs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2200, 2, 96, 96, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUmBABasCNtx"
      },
      "source": [
        "A_train = []\n",
        "B_train = []\n",
        "y_train = list(lfw_pairs_train.target)\n",
        "for i in lfw_pairs_train.pairs:\n",
        "  A_train.append(i[0])\n",
        "  B_train.append(i[1])\n",
        "\n",
        "A_train = np.array(A_train)\n",
        "B_train = np.array(B_train)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3-MJeKOCkpM"
      },
      "source": [
        "A_test = []\n",
        "B_test = []\n",
        "y_test = list(lfw_pairs_test.target)\n",
        "for i in lfw_pairs_test.pairs:\n",
        "  A_test.append(i[0])\n",
        "  B_test.append(i[1])\n",
        "  \n",
        "A_test = np.array(A_test)\n",
        "B_test = np.array(B_test)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlWgqSTANCIR"
      },
      "source": [
        "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
        "y_test = np.asarray(y_test).astype('float32').reshape((-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f5d8C1oBxg3"
      },
      "source": [
        "inputA = Input(shape=(96,96,3))\n",
        "inputB = Input(shape=(96,96,3))\n",
        "\n",
        "x = net(inputA)\n",
        "x = Model(inputs=inputA, outputs=x)\n",
        "\n",
        "y = net(inputB)\n",
        "y = Model(inputs=inputB, outputs=y)\n",
        "\n",
        "for i, layer in enumerate(y.layers):\n",
        "    layer._name = 'layer_' + str(i)\n",
        "\n",
        "# combined = Concatenate()([x.output, y.output])\n",
        "\n",
        "def euclidean_distance(vectors):\n",
        "    (featA, featB) = vectors\n",
        "    sum_squared = K.sum(K.square(featA - featB), axis=1, keepdims=True)\n",
        "    return K.sqrt(K.maximum(sum_squared, K.epsilon()))\n",
        "\n",
        "z = Lambda(euclidean_distance)([x.output, y.output])\n",
        "z = Dense(1, activation=\"sigmoid\")(z)\n",
        "\n",
        "model = Model(inputs=[x.input, y.input], outputs=z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ8v5RLxJmua"
      },
      "source": [
        "model.compile(loss=\"binary_crossentropy\", optimizer=SGD() ,metrics=['binary_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lC8yVPBE2x8Q",
        "outputId": "4ad8883d-d824-469e-d2aa-e5146745f62f"
      },
      "source": [
        "model.fit(x=[A_test, B_test], y=y_test,validation_data=([A_train[:400], B_train[:400]], y_train[:400]),epochs=25,batch_size=8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 0.4910 - binary_accuracy: 0.7670 - val_loss: 0.1251 - val_binary_accuracy: 0.9850\n",
            "Epoch 2/25\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 0.3808 - binary_accuracy: 0.8370 - val_loss: 0.1009 - val_binary_accuracy: 0.9950\n",
            "Epoch 3/25\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 0.2993 - binary_accuracy: 0.8840 - val_loss: 0.1059 - val_binary_accuracy: 0.9925\n",
            "Epoch 4/25\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 0.2658 - binary_accuracy: 0.9150 - val_loss: 0.1070 - val_binary_accuracy: 0.9900\n",
            "Epoch 5/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.2189 - binary_accuracy: 0.9490 - val_loss: 0.1109 - val_binary_accuracy: 0.9900\n",
            "Epoch 6/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.2018 - binary_accuracy: 0.9580 - val_loss: 0.1094 - val_binary_accuracy: 0.9875\n",
            "Epoch 7/25\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 0.1689 - binary_accuracy: 0.9770 - val_loss: 0.1160 - val_binary_accuracy: 0.9875\n",
            "Epoch 8/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1647 - binary_accuracy: 0.9780 - val_loss: 0.1115 - val_binary_accuracy: 0.9875\n",
            "Epoch 9/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1525 - binary_accuracy: 0.9780 - val_loss: 0.1021 - val_binary_accuracy: 0.9900\n",
            "Epoch 10/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1404 - binary_accuracy: 0.9910 - val_loss: 0.1013 - val_binary_accuracy: 0.9925\n",
            "Epoch 11/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1304 - binary_accuracy: 0.9880 - val_loss: 0.1047 - val_binary_accuracy: 0.9900\n",
            "Epoch 12/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1240 - binary_accuracy: 0.9900 - val_loss: 0.1021 - val_binary_accuracy: 0.9925\n",
            "Epoch 13/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1164 - binary_accuracy: 0.9890 - val_loss: 0.1125 - val_binary_accuracy: 0.9825\n",
            "Epoch 14/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1150 - binary_accuracy: 0.9950 - val_loss: 0.1076 - val_binary_accuracy: 0.9875\n",
            "Epoch 15/25\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 0.0975 - binary_accuracy: 0.9970 - val_loss: 0.1201 - val_binary_accuracy: 0.9775\n",
            "Epoch 16/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.1015 - binary_accuracy: 0.9910 - val_loss: 0.1097 - val_binary_accuracy: 0.9850\n",
            "Epoch 17/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0983 - binary_accuracy: 0.9950 - val_loss: 0.1115 - val_binary_accuracy: 0.9850\n",
            "Epoch 18/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0842 - binary_accuracy: 0.9980 - val_loss: 0.1097 - val_binary_accuracy: 0.9850\n",
            "Epoch 19/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0849 - binary_accuracy: 0.9960 - val_loss: 0.1203 - val_binary_accuracy: 0.9750\n",
            "Epoch 20/25\n",
            "125/125 [==============================] - 5s 43ms/step - loss: 0.0816 - binary_accuracy: 0.9950 - val_loss: 0.1083 - val_binary_accuracy: 0.9825\n",
            "Epoch 21/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0812 - binary_accuracy: 0.9960 - val_loss: 0.1058 - val_binary_accuracy: 0.9800\n",
            "Epoch 22/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0803 - binary_accuracy: 0.9950 - val_loss: 0.1070 - val_binary_accuracy: 0.9800\n",
            "Epoch 23/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0767 - binary_accuracy: 0.9980 - val_loss: 0.1192 - val_binary_accuracy: 0.9775\n",
            "Epoch 24/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0737 - binary_accuracy: 0.9950 - val_loss: 0.1124 - val_binary_accuracy: 0.9800\n",
            "Epoch 25/25\n",
            "125/125 [==============================] - 5s 42ms/step - loss: 0.0680 - binary_accuracy: 0.9980 - val_loss: 0.1111 - val_binary_accuracy: 0.9800\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f32a456b8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMCwjkYs29tS"
      },
      "source": [
        "model.save(\"face_ver2.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4phrMRxkGJeu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09aa05e9-500a-4c61-b6e7-7f2abe5d629c"
      },
      "source": [
        "model = load_model(\"face_ver.h5\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/MIP\n",
        "from PIL import Image\n",
        "def pre_process(path):\n",
        "  im = Image.open(path)\n",
        "  out = im.resize((96,96))\n",
        "  out = np.expand_dims(out, axis=0)\n",
        "  return np.array(out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/MIP\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SAGzlwE7CZ2"
      },
      "source": [
        "x =\"lfw/Akhmed_Zakayev/Akhmed_Zakayev_0002.jpg\"\n",
        "y = \"lfw/Akhmed_Zakayev/Akhmed_Zakayev_0003.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ssogXzN2tM3",
        "outputId": "462c3637-99c7-4582-d38b-f3713ed5be2d"
      },
      "source": [
        "model.predict([pre_process(x),pre_process(y)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9456991]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAnSC_0G61ZJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}